"""Critic training: learn routing success prediction.

Training data: (partial routing state, final routing score) pairs
Generated by running nextpnr router on partial routings.

This is NOT a heuristic - it's learned from ground truth.
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass

from .gnn import RoutingCritic, RoutingGraph
from .features import RoutingGraphBuilder
from ..diffusion.model import RoutingState, compute_congestion_from_latents
from ..core.routing.grid import Grid
from ..core.routing.netlist import Netlist, Net, Pin


@dataclass
class RoutingExample:
    """Training example for routing critic.

    Contains partial routing state and ground-truth outcome.
    """
    state: RoutingState
    netlist: Netlist
    grid: Grid
    final_score: float  # 0-1, from actual router
    failed_nets: int    # Number of nets that failed to route
    congestion_max: float
    timing_slack: float


class RoutingDataset(Dataset):
    """Dataset of routing states and outcomes."""

    def __init__(
        self,
        examples: List[RoutingExample],
        graph_builder: RoutingGraphBuilder
    ):
        self.examples = examples
        self.graph_builder = graph_builder

    def __len__(self) -> int:
        return len(self.examples)

    def __getitem__(self, idx: int) -> Tuple[RoutingGraph, float]:
        ex = self.examples[idx]
        graph = self.graph_builder.build_graph(ex.state, ex.netlist)
        return graph, ex.final_score


def collate_routing_graphs(
    batch: List[Tuple[RoutingGraph, float]]
) -> Tuple[RoutingGraph, torch.Tensor]:
    """Collate routing graphs into batch."""
    graphs, scores = zip(*batch)

    # Concatenate node features
    node_features = torch.cat([g.node_features for g in graphs], dim=0)

    # Offset edge indices
    edge_indices = []
    offset = 0
    for g in graphs:
        edge_indices.append(g.edge_index + offset)
        offset += g.node_features.size(0)
    edge_index = torch.cat(edge_indices, dim=1) if edge_indices else torch.zeros(2, 0, dtype=torch.long)

    # Concatenate other features
    edge_features = torch.cat([g.edge_features for g in graphs], dim=0)
    congestion = torch.cat([g.congestion for g in graphs], dim=0)
    unrouted_mask = torch.cat([g.unrouted_mask for g in graphs], dim=0)

    # Batch assignment
    batch_idx = torch.cat([
        torch.full((g.node_features.size(0),), i, dtype=torch.long)
        for i, g in enumerate(graphs)
    ])

    batched_graph = RoutingGraph(
        node_features=node_features,
        edge_index=edge_index,
        edge_features=edge_features,
        congestion=congestion,
        unrouted_mask=unrouted_mask,
        batch=batch_idx
    )

    return batched_graph, torch.tensor(scores, dtype=torch.float32)


class CriticTrainer:
    """Trainer for routing critic.

    Training loop:
    1. Sample partial routing states (from diffusion trajectories)
    2. Complete routing with nextpnr
    3. Record (partial state, final score) pairs
    4. Train critic with MSE loss
    """

    def __init__(
        self,
        critic: RoutingCritic,
        lr: float = 1e-4,
        weight_decay: float = 1e-5,
        device: str = "cuda"
    ):
        self.critic = critic.to(device)
        self.device = device

        self.optimizer = optim.AdamW(
            critic.parameters(),
            lr=lr,
            weight_decay=weight_decay
        )

        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, T_max=1000, eta_min=1e-6
        )

        # MSE loss for value prediction
        self.criterion = nn.MSELoss()

    def train_epoch(
        self,
        dataloader: DataLoader,
        log_interval: int = 100
    ) -> Dict[str, float]:
        """Train for one epoch."""
        self.critic.train()

        total_loss = 0.0
        total_mae = 0.0
        num_batches = 0

        for batch_idx, (graph, targets) in enumerate(dataloader):
            # Move to device
            graph = RoutingGraph(
                node_features=graph.node_features.to(self.device),
                edge_index=graph.edge_index.to(self.device),
                edge_features=graph.edge_features.to(self.device),
                congestion=graph.congestion.to(self.device),
                unrouted_mask=graph.unrouted_mask.to(self.device),
                batch=graph.batch.to(self.device) if graph.batch is not None else None
            )
            targets = targets.to(self.device)

            # Forward
            self.optimizer.zero_grad()
            # Pass None for shared encoder inputs (will be enhanced when data includes these)
            predictions = self.critic(
                graph,
                net_features=None,
                net_positions=None,
                congestion_map=None
            )

            # Loss
            loss = self.criterion(predictions, targets)

            # Backward
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.critic.parameters(), 1.0)
            self.optimizer.step()

            # Track metrics
            total_loss += loss.item()
            total_mae += (predictions - targets).abs().mean().item()
            num_batches += 1

            if (batch_idx + 1) % log_interval == 0:
                print(f"  Batch {batch_idx + 1}: loss={loss.item():.4f}")

        self.scheduler.step()

        return {
            "loss": total_loss / num_batches,
            "mae": total_mae / num_batches
        }

    def evaluate(self, dataloader: DataLoader) -> Dict[str, float]:
        """Evaluate on validation set."""
        self.critic.eval()

        total_loss = 0.0
        total_mae = 0.0
        num_batches = 0

        # For threshold analysis
        predictions_all = []
        targets_all = []

        with torch.no_grad():
            for graph, targets in dataloader:
                graph = RoutingGraph(
                    node_features=graph.node_features.to(self.device),
                    edge_index=graph.edge_index.to(self.device),
                    edge_features=graph.edge_features.to(self.device),
                    congestion=graph.congestion.to(self.device),
                    unrouted_mask=graph.unrouted_mask.to(self.device),
                    batch=graph.batch.to(self.device) if graph.batch is not None else None
                )
                targets = targets.to(self.device)

                predictions = self.critic(
                    graph,
                    net_features=None,
                    net_positions=None,
                    congestion_map=None
                )

                loss = self.criterion(predictions, targets)
                total_loss += loss.item()
                total_mae += (predictions - targets).abs().mean().item()
                num_batches += 1

                predictions_all.extend(predictions.cpu().tolist())
                targets_all.extend(targets.cpu().tolist())

        # Compute pruning metrics at different thresholds
        predictions_t = torch.tensor(predictions_all)
        targets_t = torch.tensor(targets_all)

        metrics = {
            "loss": total_loss / num_batches,
            "mae": total_mae / num_batches
        }

        for threshold in [0.3, 0.5, 0.7]:
            # How many would we prune?
            pruned = (predictions_t < threshold).float().mean().item()

            # Of those pruned, how many were actually bad?
            actually_bad = (targets_t < threshold).float()
            predicted_bad = (predictions_t < threshold).float()

            # Precision: of predicted bad, how many are actually bad
            if predicted_bad.sum() > 0:
                precision = (predicted_bad * actually_bad).sum() / predicted_bad.sum()
            else:
                precision = 1.0

            # Recall: of actually bad, how many did we catch
            if actually_bad.sum() > 0:
                recall = (predicted_bad * actually_bad).sum() / actually_bad.sum()
            else:
                recall = 1.0

            metrics[f"prune_rate_{threshold}"] = pruned
            metrics[f"precision_{threshold}"] = precision.item()
            metrics[f"recall_{threshold}"] = recall.item()

        return metrics

    def save_checkpoint(self, path: str) -> None:
        """Save checkpoint."""
        torch.save({
            "model_state_dict": self.critic.state_dict(),
            "optimizer_state_dict": self.optimizer.state_dict(),
            "scheduler_state_dict": self.scheduler.state_dict()
        }, path)

    def load_checkpoint(self, path: str) -> None:
        """Load checkpoint."""
        checkpoint = torch.load(path, map_location=self.device)
        self.critic.load_state_dict(checkpoint["model_state_dict"])
        self.optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
        self.scheduler.load_state_dict(checkpoint["scheduler_state_dict"])


def generate_training_data(
    netlists: List[Netlist],
    grids: List[Grid],
    router_fn,  # Function: (routing_assignment, netlist, grid) -> RoutingResult
    diffusion_model,  # For generating partial states
    samples_per_netlist: int = 100,
    device: str = "cpu"
) -> List[RoutingExample]:
    """Generate training data by sampling partial routings.

    1. Start from noise
    2. Denoise to various timesteps (partial routings)
    3. Complete with real router
    4. Record (partial, final_score) pairs

    Args:
        netlists: List of netlists to sample from
        grids: Corresponding grids for each netlist
        router_fn: Function that takes (routing_assignment, netlist, grid) -> RoutingResult
        diffusion_model: Trained diffusion model for generating partial states
        samples_per_netlist: Number of samples per netlist
        device: Device to run on

    Returns:
        List of RoutingExample for training
    """
    import torch
    from ..diffusion.sampler import initialize_routing_state

    examples = []

    for netlist, grid in zip(netlists, grids):
        num_nets = len(netlist.nets)
        if num_nets == 0:
            continue

        # Compute net features and positions for this netlist
        net_features = torch.zeros(num_nets, 8, device=device)
        net_positions = torch.zeros(num_nets, 4, device=device)
        width, height = grid.get_size()

        for i, net in enumerate(netlist.nets):
            if net.pins:
                xs = [p.x for p in net.pins]
                ys = [p.y for p in net.pins]
                min_x, max_x = min(xs), max(xs)
                min_y, max_y = min(ys), max(ys)

                net_features[i, 0] = len(net.pins) / 100.0  # fanout
                net_features[i, 1] = ((max_x - min_x) + (max_y - min_y)) / (width + height)  # HPWL

                net_positions[i, 0] = min_x / max(width, 1)
                net_positions[i, 1] = min_y / max(height, 1)
                net_positions[i, 2] = max_x / max(width, 1)
                net_positions[i, 3] = max_y / max(height, 1)

        # Estimate PIPs per net (simplified)
        pips_per_net = [max(10, len(net.pins) * 5) for net in netlist.nets]

        for sample_idx in range(samples_per_netlist):
            # Sample a random stopping timestep (partial routing depth)
            num_timesteps = getattr(diffusion_model, 'num_timesteps', 1000)
            # Sample from different stages: early (high t), middle, late (low t)
            stop_timestep = torch.randint(1, num_timesteps, (1,)).item()

            # Initialize with noise
            state = initialize_routing_state(
                num_nets=num_nets,
                pips_per_net=pips_per_net,
                num_timesteps=num_timesteps,
                device=device
            )

            # Denoise to the stopping point
            with torch.no_grad():
                while state.timestep > stop_timestep:
                    state = diffusion_model.denoise_step(
                        state, net_features, net_positions
                    )

            # Decode to routing assignment
            routing_assignment = diffusion_model.decode_routing(state, {})

            # Get ground truth score from real router
            try:
                result = router_fn(routing_assignment, netlist, grid)
                final_score = result.as_reward() if hasattr(result, 'as_reward') else float(result)
                failed_nets = 0 if result.success else num_nets
                congestion_max = getattr(result, 'congestion', 0.5)
                timing_slack = getattr(result, 'slack', 0.0)
            except Exception as e:
                # Router failed - this is a hard negative example
                final_score = 0.0
                failed_nets = num_nets
                congestion_max = 1.0
                timing_slack = -999.0

            # Create training example
            example = RoutingExample(
                state=state,
                netlist=netlist,
                grid=grid,
                final_score=final_score,
                failed_nets=failed_nets,
                congestion_max=congestion_max,
                timing_slack=timing_slack
            )
            examples.append(example)

    return examples


def generate_synthetic_training_data(
    num_examples: int = 1000,
    grid_sizes: List[Tuple[int, int]] = None,
    nets_range: Tuple[int, int] = (5, 50),
    device: str = "cpu"
) -> List[RoutingExample]:
    """Generate synthetic training data without real router.

    Creates random partial routing states with estimated scores based on
    congestion heuristics. Useful for bootstrapping critic training.

    Args:
        num_examples: Number of examples to generate
        grid_sizes: List of (width, height) tuples to sample from
        nets_range: Range of number of nets (min, max)
        device: Device to use

    Returns:
        List of synthetic RoutingExample
    """
    import random

    if grid_sizes is None:
        grid_sizes = [(10, 10), (20, 20), (50, 50)]

    examples = []

    for _ in range(num_examples):
        # Random grid size
        width, height = random.choice(grid_sizes)
        grid = Grid(width=width, height=height)

        # Random number of nets
        num_nets = random.randint(nets_range[0], nets_range[1])

        # Generate random nets
        nets = []
        for net_id in range(num_nets):
            num_pins = random.randint(2, 5)
            pins = []
            for pin_idx in range(num_pins):
                x = random.randint(0, width - 1)
                y = random.randint(0, height - 1)
                pins.append(Pin(x=x, y=y, pin_id=pin_idx))
            nets.append(Net(net_id=net_id, pins=pins, name=f"net_{net_id}"))

        netlist = Netlist(nets=nets)

        # Random partial routing state
        pips_per_net = [random.randint(10, 50) for _ in range(num_nets)]

        # Random timestep (representing routing progress)
        timestep = random.randint(0, 1000)

        # Generate random latents
        net_latents = {}
        routed_nets = set()
        for i in range(num_nets):
            latent = torch.randn(pips_per_net[i], device=device)
            # Later timesteps have more concentrated distributions
            concentration = 1.0 - (timestep / 1000.0)
            latent = latent * (1 + concentration * 5)  # More peaked for lower t
            net_latents[i] = latent

            # Mark as routed with some probability (based on timestep)
            if random.random() < (1.0 - timestep / 1000.0):
                routed_nets.add(i)

        # Compute congestion map from latents (not random!)
        congestion_map = compute_congestion_from_latents(
            net_latents=net_latents,
            netlist=netlist,
            grid_size=(width, height),
            device=device
        )

        state = RoutingState(
            net_latents=net_latents,
            timestep=timestep,
            routed_nets=routed_nets,
            congestion_map=congestion_map
        )

        # Estimate score based on heuristics
        # - More routed nets = better
        # - Lower congestion = better
        # - Later timestep (more progress) = better
        routed_fraction = len(routed_nets) / max(num_nets, 1)
        avg_congestion = congestion_map.mean().item()
        max_congestion = congestion_map.max().item()
        progress = 1.0 - (timestep / 1000.0)

        # Combine into score (0-1)
        base_score = 0.3 * routed_fraction + 0.3 * (1 - avg_congestion) + 0.4 * progress
        # Add noise
        noise = random.uniform(-0.1, 0.1)
        final_score = max(0.0, min(1.0, base_score + noise))

        example = RoutingExample(
            state=state,
            netlist=netlist,
            grid=grid,
            final_score=final_score,
            failed_nets=num_nets - len(routed_nets),
            congestion_max=congestion_map.max().item(),
            timing_slack=0.0
        )
        examples.append(example)

    return examples
